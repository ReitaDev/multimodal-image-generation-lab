# Multimodal Image Generation Lab

This lab introduces multimodal learning by guiding students to generate images from text prompts using diffusion models.

## ğŸ“˜ Contents

- `notebooks/`: The main Jupyter notebook for hands-on activities.
- `docs/`: A PDF worksheet with reflection questions and prompts.
- `instructions/`: Assignment setup and submission guidelines.

## ğŸš€ Quick Start (Google Colab)

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ReitaDev/multimodal-image-generation-lab/blob/main/notebooks/Multimodal_Image_Generation_Exercise.ipynb)

## ğŸ¯ Learning Objectives

- Understand how multimodal inputs (text + images) are encoded
- Learn the basics of Stable Diffusion for image generation
- Reflect on how prompt tuning affects generated outputs

## ğŸ› ï¸ Setup

Run the notebook in Google Colab or a local Jupyter environment with `diffusers`, `transformers`, and `torch` installed.

## âœ… Submission Instructions

Refer to the `instructions/assignment.md` file for how to complete and submit your work.
